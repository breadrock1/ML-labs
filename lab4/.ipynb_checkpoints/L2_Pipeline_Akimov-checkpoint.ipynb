{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки для работы: numpy, pandas, а также matplotlib и seaborn для визуализации данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(13, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем файл с Датасетом и просмотрим информацию о данной таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null int64\n",
      "sex         303 non-null int64\n",
      "cp          303 non-null int64\n",
      "trestbps    303 non-null int64\n",
      "chol        303 non-null int64\n",
      "fbs         303 non-null int64\n",
      "restecg     303 non-null int64\n",
      "thalach     303 non-null int64\n",
      "exang       303 non-null int64\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null int64\n",
      "ca          303 non-null int64\n",
      "thal        303 non-null int64\n",
      "target      303 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/akimg/Downloads/heart.csv', sep=',')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тренировочную и валидационную выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis='columns'),\n",
    "                                                    data['target'],\n",
    "                                                    stratify=data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создадим функцию, которая удаляет определенные колонки из данной таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_dropper(X):\n",
    "    X = X.drop(['sex', 'thalach', 'exang', 'oldpeak', 'ca'], axis='columns')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'slope', 'thal'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dropper(X_train).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим еще одну функцию, которая будет преобразовывать типы указанных колонок в таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(X_train['thal'])\n",
    "cols = ['age', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'slope', 'thal']\n",
    "\n",
    "def datatype_transform(X):\n",
    "    for col in cols:\n",
    "        X[col] = X[col].apply(lambda value: 0.5 if pd.isnull(value) else value)\n",
    "    X.loc[:, 'thal'] = X['thal'].apply(lambda title: counter.get(title, 0))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим класс, который сделает из обычной функции, принимающей матрицу признаков, шаг пайплайна, также создадим класс, который нормализует признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('functiontransformer-1',\n",
       "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                     func=<function columns_dropper at 0x7fff94e8fb70>,\n",
       "                                     inv_kw_args=None, inverse_func=None,\n",
       "                                     kw_args=None, pass_y='deprecated',\n",
       "                                     validate=False)),\n",
       "                ('functiontransformer-2',\n",
       "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                     func=<function datatype_transform at 0x7fffbc7f8f28>,\n",
       "                                     inv_kw_args=None, inverse_func=None,\n",
       "                                     kw_args=None, pass_y='deprecated',\n",
       "                                     validate=False)),\n",
       "                ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('kneighborsclassifier',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    FunctionTransformer(columns_dropper, validate=False),\n",
    "\n",
    "    FunctionTransformer(datatype_transform, validate=False),\n",
    "    MinMaxScaler(),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    ")\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578947"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраним модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеку pickle для дампа модели. Далее откроем файл для записи данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/home/akimg/Downloads/lab2_model.pickle\", 'wb') as opened_file:\n",
    "    pickle.dump(pipeline, opened_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим рузультат дампа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('functiontransformer-1',\n",
       "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                     func=<function columns_dropper at 0x7fff94e8fb70>,\n",
       "                                     inv_kw_args=None, inverse_func=None,\n",
       "                                     kw_args=None, pass_y='deprecated',\n",
       "                                     validate=False)),\n",
       "                ('functiontransformer-2',\n",
       "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                     func=<function datatype_transform at 0x7fffbc7f8f28>,\n",
       "                                     inv_kw_args=None, inverse_func=None,\n",
       "                                     kw_args=None, pass_y='deprecated',\n",
       "                                     validate=False)),\n",
       "                ('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('kneighborsclassifier',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "with open(\"/home/akimg/Downloads/lab2_model.pickle\", 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заново считаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.834983498349835"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/akimg/Downloads/heart.csv', sep=',')\n",
    "X = data.drop('target', axis='columns')\n",
    "y = data['target']\n",
    "\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраним модель первой лабы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
