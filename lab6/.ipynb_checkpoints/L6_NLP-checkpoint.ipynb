{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify Russian texts into several categories. It is best if the body of the texts is really large. To pre-process texts: normalization, lemmatization, etc. Compare embeddings. Try several classification methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/akimg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/akimg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def lemmatize(input_text):\n",
    "    tokens = nltk.word_tokenize(input_text)\n",
    "    normed_tokens = [morph.parse(s)[0].normal_form for s in tokens]\n",
    "    \n",
    "    # we also exclude stop words - all sorts of prepositions, conjunctions, etc.\n",
    "    normed_tokens = [word for word in normed_tokens if word not in nltk.corpus.stopwords.words(\"russian\")]\n",
    "    normed_tokens = [word for word in normed_tokens if word not in nltk.corpus.stopwords.words(\"english\")]\n",
    "    \n",
    "    # and punctuation marks\n",
    "    normed_tokens = [word for word in normed_tokens if word not in punctuation]\n",
    "    return ' '.join(normed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# prepare an empty data frame\n",
    "df = pd.DataFrame(columns=['text', 'class'])\n",
    "\n",
    "# these are folders in which files with texts\n",
    "dir0 = \"data/Bulgakov/\"\n",
    "dir1 = \"data/Dostoevsky/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider all our texts in a data frame indicating the class\n",
    "for filename in os.listdir(dir0):\n",
    "    with open(os.path.join(dir0, filename), encoding='utf8', errors='ignore') as file:\n",
    "        contents = lemmatize(file.read())\n",
    "    df = df.append(pd.Series({'text': contents, 'class': 0}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and for the second folder too\n",
    "for filename in os.listdir(dir1):\n",
    "    with open(os.path.join(dir1, filename), encoding='utf8', errors='ignore') as file:\n",
    "        contents = lemmatize(file.read())\n",
    "    df = df.append(pd.Series({'text': contents, 'class': 1}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>принимать внимание ежедневно дарья пётр закупа...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>царство небесный настоящий личность барский по...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>выучить « главрыба » угол мохов « б » подбегат...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>весь предмет помещаться маленький мраморный ст...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>зимой пойти бить сапог бить кирпич ребро получ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>шарик начать учиться цвета лишь исполниться че...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>далёкий идти пузатый двубокать дрянь неизвестн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>разрисовать райский цвета тарелка чёрный широк...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>глаз менее день заливаться благодарный слеза а...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>учиться читать совершенно мясо пахнуть верста ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>полдень угостить колпак кипяток стемнеть час ч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>брат пёс отведать изолировать проволока чистый...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>играть гармоника пахнуть сосиска буква белых п...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>играть гармоника пахнуть сосиска буква белых п...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>далёкий идти пузатый двубокать дрянь неизвестн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>тело изломанный битый надругаться человек дост...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>это дело любитель – весь равно калоша лизать б...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>хотя ещё накануне предчувствовать именно сегод...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>обладатель плащ капюшон молодая человек год дв...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ведать судья происходить душа иван фёдор знать...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>немой довольно широкий толстый плащ рукав огро...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>особенно приметный это лицо мёртвый бледность ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ещё петербургский уезд какой-то фабрика старин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>лёт генерал епанчин ещё говориться самый сок п...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>весь девица епанчин барышня здоровый цветущий ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>кроме чай кофей сыр мёд масло особый оладья из...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>генерал епанчин жить собственный свой дом неск...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>вагон третье класс рассвет очутиться друг прот...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>известно иван фёдор епанчин — человек образова...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>везти карта играть чрезвычайно большой намерен...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>правда характер весьма часто слушаться подчиня...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>чашка кофей выпиваться барышня ещё ранний ровн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>лицо молодой человек приятный тонкий сухой бес...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>небольшой рост год двадцать семь курчавый черн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text class\n",
       "0   принимать внимание ежедневно дарья пётр закупа...     0\n",
       "1   царство небесный настоящий личность барский по...     0\n",
       "2   выучить « главрыба » угол мохов « б » подбегат...     0\n",
       "3   весь предмет помещаться маленький мраморный ст...     0\n",
       "4   зимой пойти бить сапог бить кирпич ребро получ...     0\n",
       "5   шарик начать учиться цвета лишь исполниться че...     0\n",
       "6   далёкий идти пузатый двубокать дрянь неизвестн...     0\n",
       "7   разрисовать райский цвета тарелка чёрный широк...     0\n",
       "8   глаз менее день заливаться благодарный слеза а...     0\n",
       "9   учиться читать совершенно мясо пахнуть верста ...     0\n",
       "10  полдень угостить колпак кипяток стемнеть час ч...     0\n",
       "11  брат пёс отведать изолировать проволока чистый...     0\n",
       "12  играть гармоника пахнуть сосиска буква белых п...     0\n",
       "13  играть гармоника пахнуть сосиска буква белых п...     0\n",
       "14  далёкий идти пузатый двубокать дрянь неизвестн...     0\n",
       "15  тело изломанный битый надругаться человек дост...     0\n",
       "16  это дело любитель – весь равно калоша лизать б...     0\n",
       "17  хотя ещё накануне предчувствовать именно сегод...     1\n",
       "18  обладатель плащ капюшон молодая человек год дв...     1\n",
       "19  ведать судья происходить душа иван фёдор знать...     1\n",
       "20  немой довольно широкий толстый плащ рукав огро...     1\n",
       "21  особенно приметный это лицо мёртвый бледность ...     1\n",
       "22  ещё петербургский уезд какой-то фабрика старин...     1\n",
       "23  лёт генерал епанчин ещё говориться самый сок п...     1\n",
       "24  весь девица епанчин барышня здоровый цветущий ...     1\n",
       "25  кроме чай кофей сыр мёд масло особый оладья из...     1\n",
       "26  генерал епанчин жить собственный свой дом неск...     1\n",
       "27  вагон третье класс рассвет очутиться друг прот...     1\n",
       "28  известно иван фёдор епанчин — человек образова...     1\n",
       "29  везти карта играть чрезвычайно большой намерен...     1\n",
       "30  правда характер весьма часто слушаться подчиня...     1\n",
       "31  чашка кофей выпиваться барышня ещё ранний ровн...     1\n",
       "32  лицо молодой человек приятный тонкий сухой бес...     1\n",
       "33  небольшой рост год двадцать семь курчавый черн...     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['class'], test_size=0.4, stratify=df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words-embedding\n",
    "\n",
    "Of course, mathematical methods are not able to work with clear text. It is time to get embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bof_vect = CountVectorizer()\n",
    "bof_vect.fit(np.hstack([X_train, X_test]))\n",
    "bof_train = bof_vect.transform(X_train)\n",
    "bof_test = bof_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bof_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1051)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bof_train.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1051)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mean_bof = np.sum(bof_train[y_train.equals(0)], axis=0)\n",
    "r_mean_bof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_mean_bof = np.sum(bof_train[y_train.equals(1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ruki</th>\n",
       "      <th>leningrad</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952860</td>\n",
       "      <td>0.952860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963845</td>\n",
       "      <td>0.963845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.879239</td>\n",
       "      <td>0.879239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.965497</td>\n",
       "      <td>0.965497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.942896</td>\n",
       "      <td>0.942896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.932580</td>\n",
       "      <td>0.932580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.958655</td>\n",
       "      <td>0.958655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.979328</td>\n",
       "      <td>0.979328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.947777</td>\n",
       "      <td>0.947777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.894591</td>\n",
       "      <td>0.894591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.912159</td>\n",
       "      <td>0.912159</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.929727</td>\n",
       "      <td>0.929727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.939277</td>\n",
       "      <td>0.939277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ruki  leningrad  predict  class\n",
       "0   0.952860   0.952860      1.0    0.0\n",
       "1   0.963845   0.963845      1.0    1.0\n",
       "2   0.879239   0.879239      1.0    1.0\n",
       "3   0.965497   0.965497      1.0    1.0\n",
       "4   0.942896   0.942896      1.0    0.0\n",
       "5   0.932580   0.932580      1.0    1.0\n",
       "6   0.958655   0.958655      1.0    0.0\n",
       "7   0.979328   0.979328      1.0    1.0\n",
       "8   1.000000   1.000000      1.0    0.0\n",
       "9   0.947777   0.947777      1.0    1.0\n",
       "10  0.894591   0.894591      1.0    1.0\n",
       "11  0.912159   0.912159      1.0    0.0\n",
       "12  0.929727   0.929727      1.0    0.0\n",
       "13  0.939277   0.939277      1.0    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "bof_r = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=r_mean_bof)\n",
    "bof_l = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=l_mean_bof)\n",
    "\n",
    "bof_results = pd.DataFrame([\n",
    "    bof_r,\n",
    "    bof_l,\n",
    "    np.maximum(bof_r, bof_l) == bof_l,\n",
    "    y_test], index=[\"ruki\", \"leningrad\", \"predict\", \"class\"]).T.astype(np.float)\n",
    "bof_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     зимой пойти бить сапог бить кирпич ребро получ...\n",
      "28    известно иван фёдор епанчин — человек образова...\n",
      "32    лицо молодой человек приятный тонкий сухой бес...\n",
      "26    генерал епанчин жить собственный свой дом неск...\n",
      "11    брат пёс отведать изолировать проволока чистый...\n",
      "31    чашка кофей выпиваться барышня ещё ранний ровн...\n",
      "9     учиться читать совершенно мясо пахнуть верста ...\n",
      "20    немой довольно широкий толстый плащ рукав огро...\n",
      "2     выучить « главрыба » угол мохов « б » подбегат...\n",
      "23    лёт генерал епанчин ещё говориться самый сок п...\n",
      "29    везти карта играть чрезвычайно большой намерен...\n",
      "6     далёкий идти пузатый двубокать дрянь неизвестн...\n",
      "5     шарик начать учиться цвета лишь исполниться че...\n",
      "8     глаз менее день заливаться благодарный слеза а...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(bof_results['predict'], bof_results['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akimg/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier().fit(bof_train.toarray(), y_train.tolist()).score(bof_test.toarray(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(np.hstack([X_train, X_test]))\n",
    "tfidf_train = tfidf_vect.transform(X_train)\n",
    "tfidf_test = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1051)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1051)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mean_tfidf = np.sum(tfidf_train[y_train.equals(0)], axis=0)\n",
    "r_mean_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_mean_tfidf = np.sum(tfidf_train[y_train.equals(1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ruki</th>\n",
       "      <th>leningrad</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989062</td>\n",
       "      <td>0.989062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975114</td>\n",
       "      <td>0.975114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.959948</td>\n",
       "      <td>0.959948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976519</td>\n",
       "      <td>0.976519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.972807</td>\n",
       "      <td>0.972807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.946998</td>\n",
       "      <td>0.946998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.978618</td>\n",
       "      <td>0.978618</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.980270</td>\n",
       "      <td>0.980270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.980662</td>\n",
       "      <td>0.980662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.972609</td>\n",
       "      <td>0.972609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.937372</td>\n",
       "      <td>0.937372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.983523</td>\n",
       "      <td>0.983523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.975735</td>\n",
       "      <td>0.975735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ruki  leningrad  predict  class\n",
       "0   0.989062   0.989062      1.0    0.0\n",
       "1   0.975114   0.975114      1.0    1.0\n",
       "2   0.959948   0.959948      1.0    1.0\n",
       "3   0.976519   0.976519      1.0    1.0\n",
       "4   0.972807   0.972807      1.0    0.0\n",
       "5   0.946998   0.946998      1.0    1.0\n",
       "6   0.978618   0.978618      1.0    0.0\n",
       "7   0.980270   0.980270      1.0    1.0\n",
       "8   1.000000   1.000000      1.0    0.0\n",
       "9   0.980662   0.980662      1.0    1.0\n",
       "10  0.972609   0.972609      1.0    1.0\n",
       "11  0.937372   0.937372      1.0    0.0\n",
       "12  0.983523   0.983523      1.0    0.0\n",
       "13  0.975735   0.975735      1.0    0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_r = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=r_mean_tfidf)\n",
    "tfidf_l = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=l_mean_tfidf)\n",
    "\n",
    "tfidf_results = pd.DataFrame([\n",
    "    tfidf_r,\n",
    "    tfidf_l,\n",
    "    np.maximum(tfidf_r, tfidf_l) == tfidf_l,\n",
    "    y_test], index=[\"ruki\", \"leningrad\", \"predict\", \"class\"]).T.astype(np.float)\n",
    "tfidf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(tfidf_results['predict'], tfidf_results['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akimg/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier().fit(tfidf_train.toarray(), y_train.tolist()).score(tfidf_test.toarray(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec-embedding\n",
    "\n",
    "Since w2v is not a sklearn classifier, it will output data of a slightly different type at the output, and this will need to be taken into account in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "X_train_w2v = X_train.apply(str.split)\n",
    "X_test_w2v = X_test.apply(str.split)\n",
    "w2v_vect = Word2Vec(np.hstack([X_train_w2v, X_test_w2v]), size=40, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30    [правда, характер, весьма, часто, слушаться, п...\n",
       "21    [особенно, приметный, это, лицо, мёртвый, блед...\n",
       "14    [далёкий, идти, пузатый, двубокать, дрянь, неи...\n",
       "16    [это, дело, любитель, –, весь, равно, калоша, ...\n",
       "10    [полдень, угостить, колпак, кипяток, стемнеть,...\n",
       "24    [весь, девица, епанчин, барышня, здоровый, цве...\n",
       "3     [весь, предмет, помещаться, маленький, мраморн...\n",
       "25    [кроме, чай, кофей, сыр, мёд, масло, особый, о...\n",
       "19    [ведать, судья, происходить, душа, иван, фёдор...\n",
       "15    [тело, изломанный, битый, надругаться, человек...\n",
       "22    [ещё, петербургский, уезд, какой-то, фабрика, ...\n",
       "7     [разрисовать, райский, цвета, тарелка, чёрный,...\n",
       "12    [играть, гармоника, пахнуть, сосиска, буква, б...\n",
       "0     [принимать, внимание, ежедневно, дарья, пётр, ...\n",
       "13    [играть, гармоника, пахнуть, сосиска, буква, б...\n",
       "1     [царство, небесный, настоящий, личность, барск...\n",
       "17    [хотя, ещё, накануне, предчувствовать, именно,...\n",
       "27    [вагон, третье, класс, рассвет, очутиться, дру...\n",
       "18    [обладатель, плащ, капюшон, молодая, человек, ...\n",
       "33    [небольшой, рост, год, двадцать, семь, курчавы...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do various interesting things with Word-Tu-Century. For example, with the following command, we can display the words that turned out to be closest in value to the given word in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('широкий', 0.30680638551712036),\n",
       " ('–', 0.20665977895259857),\n",
       " ('половина', 0.20610211789608002),\n",
       " ('друг', 0.20218273997306824),\n",
       " ('сыр', 0.1472751349210739),\n",
       " ('весь', 0.1371825486421585),\n",
       " ('свой', 0.12968699634075165),\n",
       " ('первое', 0.12856897711753845),\n",
       " ('случай', 0.09170875698328018),\n",
       " ('правда', 0.07748904079198837)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vect.most_similar(positive=\"пёс\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('самый', 0.3904285132884979),\n",
       " ('слово', 0.21938388049602509),\n",
       " ('это', 0.15510502457618713),\n",
       " ('лицо', 0.1491074562072754),\n",
       " ('хвост', 0.13058458268642426),\n",
       " ('оба', 0.12605684995651245),\n",
       " ('кроме', 0.11542735993862152),\n",
       " ('—', 0.1143377274274826),\n",
       " ('епанчин', 0.09248550236225128),\n",
       " ('«', 0.07219742983579636)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vect.most_similar(negative=[\"пёс\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем тексты песен в вектора - возьмем сумму векторов всех слов, которые входят в песню"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30    [0.0020051587, -0.0006808024, 0.0023217082, -0...\n",
       "21    [0.0036189307, 0.0026274037, 0.0017450843, -0....\n",
       "14    [0.00062815216, 0.005071218, 0.0028173197, -0....\n",
       "16    [0.0027219453, 0.00015778514, 0.0013914456, 0....\n",
       "10    [0.0043437425, 0.0029992529, 0.0031090537, 0.0...\n",
       "24    [-8.7817316e-05, -0.00048067002, 0.005580824, ...\n",
       "3     [0.0052567385, 0.00019174663, 0.0018956842, 0....\n",
       "25    [0.0062761335, 0.0032825968, 0.002430827, 0.00...\n",
       "19    [-0.00049060123, -0.00036905013, -0.0015041415...\n",
       "15    [0.006450089, -0.0022294924, 1.9380124e-05, -0...\n",
       "22    [0.0025990412, 0.0011180022, 0.0010021958, 0.0...\n",
       "7     [0.0006040912, -0.0011425489, 0.0032773723, -0...\n",
       "12    [0.0056627505, 0.0015902696, 0.0035911298, -0....\n",
       "0     [0.0052800537, 0.006135592, 0.004443416, -0.00...\n",
       "13    [0.0056627505, 0.0015902696, 0.0035911298, -0....\n",
       "1     [0.005046911, 0.0034308673, 0.0050926856, 0.00...\n",
       "17    [0.0021758946, 0.0028172277, 0.0040840674, 0.0...\n",
       "27    [0.0027608175, -0.0027356942, 0.0031221774, 0....\n",
       "18    [0.009525365, 0.002145579, 0.0029156338, 0.003...\n",
       "33    [0.008008603, 0.0003952202, 0.0016424475, 0.00...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text2vec(text):\n",
    "    # We average the word vectors\n",
    "    vecs = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            vecs.append(w2v_vect[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return np.sum(vecs, axis=0) / len(vecs)\n",
    "\n",
    "w2v_train = X_train_w2v.apply(text2vec)\n",
    "w2v_test = X_test_w2v.apply(text2vec)\n",
    "w2v_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.2800537e-03,  6.1355918e-03,  4.4434159e-03, -2.3759922e-03,\n",
       "       -2.8852476e-03,  1.0198847e-03, -2.5366426e-03, -3.2801889e-03,\n",
       "       -3.7500265e-03, -3.7477454e-03,  3.3762045e-03, -2.3114053e-03,\n",
       "       -3.6823575e-04,  7.1259780e-04, -3.7706990e-03, -1.6813326e-03,\n",
       "        1.1189969e-03,  2.8899021e-03,  5.2827261e-03, -1.0071065e-03,\n",
       "        2.5704191e-03,  4.6943624e-05, -1.1923875e-03,  2.1157840e-03,\n",
       "        1.7035749e-03, -6.2530213e-03, -1.7998546e-03, -4.3732221e-03,\n",
       "        7.8334320e-05, -2.2844190e-03, -2.2270882e-03, -4.1759899e-04,\n",
       "        1.4266969e-03,  3.1164780e-03, -6.9710556e-03,  3.7443030e-03,\n",
       "       -4.6109534e-03, -2.2606216e-03, -3.0501306e-03,  3.4615404e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train = np.dstack(w2v_train)[0]\n",
    "w2v_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_test = np.dstack(w2v_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mean_w2v = np.sum(w2v_train[:, y_train == 0], axis=1)\n",
    "r_mean_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_mean_w2v = np.sum(w2v_train[:, y_train == 1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04165722,  0.01779496,  0.02922862, -0.00677199, -0.01690252,\n",
       "        0.00222621, -0.00319195, -0.04988823,  0.00041088, -0.01605525,\n",
       "       -0.00628722, -0.00379488, -0.01941233, -0.01479384, -0.00252264,\n",
       "       -0.03452507, -0.00341374,  0.00763343,  0.02131335, -0.02114879,\n",
       "       -0.01616263,  0.00354776, -0.00084967, -0.00097331,  0.01461923,\n",
       "       -0.0175407 , -0.00566027, -0.01091546, -0.00244835, -0.01284909,\n",
       "        0.00571721,  0.00596794, -0.0139887 , -0.00713897, -0.01410007,\n",
       "        0.00848586, -0.03263284,  0.00109359,  0.00618847,  0.02020013],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mean_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03639153,  0.00811981,  0.02334082,  0.00578581, -0.01950352,\n",
       "       -0.0032452 ,  0.02410904, -0.01117448,  0.01246825, -0.00154648,\n",
       "       -0.01920532,  0.00265025,  0.00625496, -0.00479666, -0.00172858,\n",
       "       -0.01270933,  0.0049363 ,  0.01996669,  0.0239169 , -0.01430546,\n",
       "       -0.0011006 ,  0.00490209, -0.00260028, -0.00401581,  0.01536079,\n",
       "        0.01576239,  0.01426886, -0.0356225 , -0.02328332, -0.00462142,\n",
       "        0.01079347, -0.03714938, -0.00253065, -0.01166139,  0.00425046,\n",
       "       -0.01020377, -0.02850923,  0.00339461,  0.00663321, -0.00440668],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_mean_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>l</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.724402</td>\n",
       "      <td>0.629545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828942</td>\n",
       "      <td>0.425812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.785144</td>\n",
       "      <td>0.468837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786409</td>\n",
       "      <td>0.687019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.328945</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.712283</td>\n",
       "      <td>0.551921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.591634</td>\n",
       "      <td>0.795179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.787078</td>\n",
       "      <td>0.987960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.650896</td>\n",
       "      <td>0.951145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.790382</td>\n",
       "      <td>0.366508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.579619</td>\n",
       "      <td>0.774001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.604664</td>\n",
       "      <td>0.965650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.649387</td>\n",
       "      <td>0.704424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.179888</td>\n",
       "      <td>0.522363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           r         l  predict  class\n",
       "0   0.724402  0.629545      0.0    0.0\n",
       "1   0.828942  0.425812      0.0    1.0\n",
       "2   0.785144  0.468837      0.0    1.0\n",
       "3   0.786409  0.687019      0.0    1.0\n",
       "4   0.328945  0.661290      1.0    0.0\n",
       "5   0.712283  0.551921      0.0    1.0\n",
       "6   0.591634  0.795179      1.0    0.0\n",
       "7   0.787078  0.987960      1.0    1.0\n",
       "8   0.650896  0.951145      1.0    0.0\n",
       "9   0.790382  0.366508      0.0    1.0\n",
       "10  0.579619  0.774001      1.0    1.0\n",
       "11  0.604664  0.965650      1.0    0.0\n",
       "12  0.649387  0.704424      1.0    0.0\n",
       "13  0.179888  0.522363      1.0    0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "w2v_r = np.apply_along_axis(cosine, 0, w2v_test, v=r_mean_w2v)\n",
    "w2v_l = np.apply_along_axis(cosine, 0, w2v_test, v=l_mean_w2v)\n",
    "\n",
    "w2v_results = pd.DataFrame([\n",
    "    w2v_r,\n",
    "    w2v_l,\n",
    "    np.maximum(w2v_r, w2v_l) == w2v_l,\n",
    "    y_test], index=[\"r\", \"l\", \"predict\", \"class\"]).T.astype(np.float)\n",
    "w2v_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21428571428571427"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(w2v_results['predict'], w2v_results['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akimg/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier().fit(w2v_train.T, y_train.tolist()).score(w2v_test.T, y_test.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
