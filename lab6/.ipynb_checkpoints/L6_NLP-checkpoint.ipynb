{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify Russian texts into several categories. It is best if the body of the texts is really large. To pre-process texts: normalization, lemmatization, etc. Compare embeddings. Try several classification methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/akimg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/akimg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def lemmatize(input_text):\n",
    "    tokens = nltk.word_tokenize(input_text)\n",
    "    normed_tokens = [morph.parse(s)[0].normal_form for s in tokens]\n",
    "    \n",
    "    # we also exclude stop words - all sorts of prepositions, conjunctions, etc.\n",
    "    normed_tokens = [word for word in normed_tokens if word not in nltk.corpus.stopwords.words(\"russian\")]\n",
    "    normed_tokens = [word for word in normed_tokens if word not in nltk.corpus.stopwords.words(\"english\")]\n",
    "    \n",
    "    # and punctuation marks\n",
    "    normed_tokens = [word for word in normed_tokens if word not in punctuation]\n",
    "    return ' '.join(normed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# prepare an empty data frame\n",
    "df = pd.DataFrame(columns=['text', 'class'])\n",
    "\n",
    "# these are folders in which files with texts\n",
    "dir0 = \"data/Bulgakov/\"\n",
    "dir1 = \"data/Dostoevsky/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider all our texts in a data frame indicating the class\n",
    "for filename in os.listdir(dir0):\n",
    "    with open(os.path.join(dir0, filename), encoding='utf8', errors='ignore') as file:\n",
    "        contents = lemmatize(file.read())\n",
    "    df = df.append(pd.Series({'text': contents, 'class': 0}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and for the second folder too\n",
    "for filename in os.listdir(dir1):\n",
    "    with open(os.path.join(dir1, filename), encoding='utf8', errors='ignore') as file:\n",
    "        contents = lemmatize(file.read())\n",
    "    df = df.append(pd.Series({'text': contents, 'class': 1}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>принимать внимание ежедневно дарья пётр закупа...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>царство небесный настоящий личность барский по...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>выучить « главрыба » угол мохов « б » подбегат...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>весь предмет помещаться маленький мраморный ст...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>зимой пойти бить сапог бить кирпич ребро получ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>шарик начать учиться цвета лишь исполниться че...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>далёкий идти пузатый двубокать дрянь неизвестн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>разрисовать райский цвета тарелка чёрный широк...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>глаз менее день заливаться благодарный слеза а...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>учиться читать совершенно мясо пахнуть верста ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>полдень угостить колпак кипяток стемнеть час ч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>брат пёс отведать изолировать проволока чистый...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>играть гармоника пахнуть сосиска буква белых п...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>играть гармоника пахнуть сосиска буква белых п...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>далёкий идти пузатый двубокать дрянь неизвестн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>тело изломанный битый надругаться человек дост...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>это дело любитель – весь равно калоша лизать б...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>хотя ещё накануне предчувствовать именно сегод...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>обладатель плащ капюшон молодая человек год дв...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ведать судья происходить душа иван фёдор знать...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>немой довольно широкий толстый плащ рукав огро...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>особенно приметный это лицо мёртвый бледность ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ещё петербургский уезд какой-то фабрика старин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>лёт генерал епанчин ещё говориться самый сок п...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>весь девица епанчин барышня здоровый цветущий ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>кроме чай кофей сыр мёд масло особый оладья из...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>генерал епанчин жить собственный свой дом неск...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>вагон третье класс рассвет очутиться друг прот...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>известно иван фёдор епанчин — человек образова...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>везти карта играть чрезвычайно большой намерен...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>правда характер весьма часто слушаться подчиня...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>чашка кофей выпиваться барышня ещё ранний ровн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>лицо молодой человек приятный тонкий сухой бес...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>небольшой рост год двадцать семь курчавый черн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text class\n",
       "0   принимать внимание ежедневно дарья пётр закупа...     0\n",
       "1   царство небесный настоящий личность барский по...     0\n",
       "2   выучить « главрыба » угол мохов « б » подбегат...     0\n",
       "3   весь предмет помещаться маленький мраморный ст...     0\n",
       "4   зимой пойти бить сапог бить кирпич ребро получ...     0\n",
       "5   шарик начать учиться цвета лишь исполниться че...     0\n",
       "6   далёкий идти пузатый двубокать дрянь неизвестн...     0\n",
       "7   разрисовать райский цвета тарелка чёрный широк...     0\n",
       "8   глаз менее день заливаться благодарный слеза а...     0\n",
       "9   учиться читать совершенно мясо пахнуть верста ...     0\n",
       "10  полдень угостить колпак кипяток стемнеть час ч...     0\n",
       "11  брат пёс отведать изолировать проволока чистый...     0\n",
       "12  играть гармоника пахнуть сосиска буква белых п...     0\n",
       "13  играть гармоника пахнуть сосиска буква белых п...     0\n",
       "14  далёкий идти пузатый двубокать дрянь неизвестн...     0\n",
       "15  тело изломанный битый надругаться человек дост...     0\n",
       "16  это дело любитель – весь равно калоша лизать б...     0\n",
       "17  хотя ещё накануне предчувствовать именно сегод...     1\n",
       "18  обладатель плащ капюшон молодая человек год дв...     1\n",
       "19  ведать судья происходить душа иван фёдор знать...     1\n",
       "20  немой довольно широкий толстый плащ рукав огро...     1\n",
       "21  особенно приметный это лицо мёртвый бледность ...     1\n",
       "22  ещё петербургский уезд какой-то фабрика старин...     1\n",
       "23  лёт генерал епанчин ещё говориться самый сок п...     1\n",
       "24  весь девица епанчин барышня здоровый цветущий ...     1\n",
       "25  кроме чай кофей сыр мёд масло особый оладья из...     1\n",
       "26  генерал епанчин жить собственный свой дом неск...     1\n",
       "27  вагон третье класс рассвет очутиться друг прот...     1\n",
       "28  известно иван фёдор епанчин — человек образова...     1\n",
       "29  везти карта играть чрезвычайно большой намерен...     1\n",
       "30  правда характер весьма часто слушаться подчиня...     1\n",
       "31  чашка кофей выпиваться барышня ещё ранний ровн...     1\n",
       "32  лицо молодой человек приятный тонкий сухой бес...     1\n",
       "33  небольшой рост год двадцать семь курчавый черн...     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['class'], test_size=0.4, stratify=df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words-embedding\n",
    "\n",
    "Of course, mathematical methods are not able to work with clear text. It is time to get embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bof_vect = CountVectorizer()\n",
    "bof_vect.fit(np.hstack([X_train, X_test]))\n",
    "bof_train = bof_vect.transform(X_train)\n",
    "bof_test = bof_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bof_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1051)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bof_train.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1051)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_mean_bof = np.sum(bof_train[y_train.equals(0)], axis=0)\n",
    "B_mean_bof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_mean_bof = np.sum(bof_train[y_train.equals(1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bulgakov</th>\n",
       "      <th>Dostoevsky</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.848887</td>\n",
       "      <td>0.848887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.948794</td>\n",
       "      <td>0.948794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.937699</td>\n",
       "      <td>0.937699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.959888</td>\n",
       "      <td>0.959888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.984099</td>\n",
       "      <td>0.984099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.949716</td>\n",
       "      <td>0.949716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.974858</td>\n",
       "      <td>0.974858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.960482</td>\n",
       "      <td>0.960482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.916779</td>\n",
       "      <td>0.916779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.961595</td>\n",
       "      <td>0.961595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.960089</td>\n",
       "      <td>0.960089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.934136</td>\n",
       "      <td>0.934136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.835965</td>\n",
       "      <td>0.835965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.965650</td>\n",
       "      <td>0.965650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bulgakov  Dostoevsky  predict  class\n",
       "0   0.848887    0.848887      1.0    0.0\n",
       "1   0.948794    0.948794      1.0    0.0\n",
       "2   0.937699    0.937699      1.0    1.0\n",
       "3   0.959888    0.959888      1.0    0.0\n",
       "4   0.984099    0.984099      1.0    0.0\n",
       "5   0.949716    0.949716      1.0    1.0\n",
       "6   0.974858    0.974858      1.0    1.0\n",
       "7   0.960482    0.960482      1.0    1.0\n",
       "8   0.916779    0.916779      1.0    0.0\n",
       "9   0.961595    0.961595      1.0    1.0\n",
       "10  0.960089    0.960089      1.0    1.0\n",
       "11  0.934136    0.934136      1.0    1.0\n",
       "12  0.835965    0.835965      1.0    0.0\n",
       "13  0.965650    0.965650      1.0    0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "bof_B = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=B_mean_bof)\n",
    "bof_D = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=D_mean_bof)\n",
    "\n",
    "bof_results = pd.DataFrame([\n",
<<<<<<< HEAD
    "    bof_B,\n",
    "    bof_D,\n",
    "    np.maximum(bof_B, bof_D) == bof_D,\n",
    "    y_test], index=[\"Bulgakov\", \"Dostoevsky\", \"predict\", \"class\"]).T.astype(np.float)\n",
=======
    "    bof_r,\n",
    "    bof_l,\n",
    "    np.maximum(bof_r, bof_l) == bof_l,\n",
    "    y_test], index=[\"Bulgakov\", \"Tolstoy\", \"predict\", \"class\"]).T.astype(np.float)\n",
>>>>>>> 02f68ff1eea8be139145b9dc5fd9e9fea4ffc987
    "bof_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    тело изломанный битый надругаться человек дост...\n",
      "5     шарик начать учиться цвета лишь исполниться че...\n",
      "21    особенно приметный это лицо мёртвый бледность ...\n",
      "1     царство небесный настоящий личность барский по...\n",
      "7     разрисовать райский цвета тарелка чёрный широк...\n",
      "32    лицо молодой человек приятный тонкий сухой бес...\n",
      "26    генерал епанчин жить собственный свой дом неск...\n",
      "19    ведать судья происходить душа иван фёдор знать...\n",
      "11    брат пёс отведать изолировать проволока чистый...\n",
      "29    везти карта играть чрезвычайно большой намерен...\n",
      "17    хотя ещё накануне предчувствовать именно сегод...\n",
      "25    кроме чай кофей сыр мёд масло особый оладья из...\n",
      "13    играть гармоника пахнуть сосиска буква белых п...\n",
      "4     зимой пойти бить сапог бить кирпич ребро получ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(bof_results['predict'], bof_results['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akimg/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier().fit(bof_train.toarray(), y_train.tolist()).score(bof_test.toarray(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(np.hstack([X_train, X_test]))\n",
    "tfidf_train = tfidf_vect.transform(X_train)\n",
    "tfidf_test = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.11353972, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.17604009,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1051)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1051)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_mean_tfidf = np.sum(tfidf_train[y_train.equals(0)], axis=0)\n",
    "B_mean_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_mean_tfidf = np.sum(tfidf_train[y_train.equals(1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bulgakov</th>\n",
       "      <th>Dostoevsky</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.918210</td>\n",
       "      <td>0.918210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.978813</td>\n",
       "      <td>0.978813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.971765</td>\n",
       "      <td>0.971765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983551</td>\n",
       "      <td>0.983551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.985338</td>\n",
       "      <td>0.985338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.979326</td>\n",
       "      <td>0.979326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.974188</td>\n",
       "      <td>0.974188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.968629</td>\n",
       "      <td>0.968629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.989388</td>\n",
       "      <td>0.989388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.974727</td>\n",
       "      <td>0.974727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.967858</td>\n",
       "      <td>0.967858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.904950</td>\n",
       "      <td>0.904950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.980410</td>\n",
       "      <td>0.980410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bulgakov  Dostoevsky  predict  class\n",
       "0   0.918210    0.918210      1.0    0.0\n",
       "1   0.966102    0.966102      1.0    0.0\n",
       "2   0.978813    0.978813      1.0    1.0\n",
       "3   0.971765    0.971765      1.0    0.0\n",
       "4   0.983551    0.983551      1.0    0.0\n",
       "5   0.985338    0.985338      1.0    1.0\n",
       "6   0.979326    0.979326      1.0    1.0\n",
       "7   0.974188    0.974188      1.0    1.0\n",
       "8   0.968629    0.968629      1.0    0.0\n",
       "9   0.989388    0.989388      1.0    1.0\n",
       "10  0.974727    0.974727      1.0    1.0\n",
       "11  0.967858    0.967858      1.0    1.0\n",
       "12  0.904950    0.904950      1.0    0.0\n",
       "13  0.980410    0.980410      1.0    0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_B = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=B_mean_tfidf)\n",
    "tfidf_D = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=D_mean_tfidf)\n",
    "\n",
    "tfidf_results = pd.DataFrame([\n",
<<<<<<< HEAD
    "    tfidf_B,\n",
    "    tfidf_D,\n",
    "    np.maximum(tfidf_B, tfidf_D) == tfidf_D,\n",
    "    y_test], index=[\"Bulgakov\", \"Dostoevsky\", \"predict\", \"class\"]).T.astype(np.float)\n",
=======
    "    tfidf_r,\n",
    "    tfidf_l,\n",
    "    np.maximum(tfidf_r, tfidf_l) == tfidf_l,\n",
    "    y_test], index=[\"Bulgakov\", \"Tolstoy\", \"predict\", \"class\"]).T.astype(np.float)\n",
>>>>>>> 02f68ff1eea8be139145b9dc5fd9e9fea4ffc987
    "tfidf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(tfidf_results['predict'], tfidf_results['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akimg/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier().fit(tfidf_train.toarray(), y_train.tolist()).score(tfidf_test.toarray(), y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec-embedding\n",
    "\n",
    "Since w2v is not a sklearn classifier, it will output data of a slightly different type at the output, and this will need to be taken into account in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "X_train_w2v = X_train.apply(str.split)\n",
    "X_test_w2v = X_test.apply(str.split)\n",
    "w2v_vect = Word2Vec(np.hstack([X_train_w2v, X_test_w2v]), size=40, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     [глаз, менее, день, заливаться, благодарный, с...\n",
       "0     [принимать, внимание, ежедневно, дарья, пётр, ...\n",
       "6     [далёкий, идти, пузатый, двубокать, дрянь, неи...\n",
       "2     [выучить, «, главрыба, », угол, мохов, «, б, »...\n",
       "28    [известно, иван, фёдор, епанчин, —, человек, о...\n",
       "9     [учиться, читать, совершенно, мясо, пахнуть, в...\n",
       "10    [полдень, угостить, колпак, кипяток, стемнеть,...\n",
       "3     [весь, предмет, помещаться, маленький, мраморн...\n",
       "12    [играть, гармоника, пахнуть, сосиска, буква, б...\n",
       "18    [обладатель, плащ, капюшон, молодая, человек, ...\n",
       "31    [чашка, кофей, выпиваться, барышня, ещё, ранни...\n",
       "33    [небольшой, рост, год, двадцать, семь, курчавы...\n",
       "22    [ещё, петербургский, уезд, какой-то, фабрика, ...\n",
       "24    [весь, девица, епанчин, барышня, здоровый, цве...\n",
       "27    [вагон, третье, класс, рассвет, очутиться, дру...\n",
       "20    [немой, довольно, широкий, толстый, плащ, рука...\n",
       "30    [правда, характер, весьма, часто, слушаться, п...\n",
       "16    [это, дело, любитель, –, весь, равно, калоша, ...\n",
       "14    [далёкий, идти, пузатый, двубокать, дрянь, неи...\n",
       "23    [лёт, генерал, епанчин, ещё, говориться, самый...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do various interesting things with Word-Tu-Century. For example, with the following command, we can display the words that turned out to be closest in value to the given word in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('это', 0.27373823523521423),\n",
       " ('голова', 0.271831750869751),\n",
       " ('чёрный', 0.23512785136699677),\n",
       " ('широкий', 0.22983548045158386),\n",
       " ('епанчин', 0.21778567135334015),\n",
       " ('весь', 0.17786243557929993),\n",
       " ('–', 0.14750254154205322),\n",
       " ('человек', 0.09247994422912598),\n",
       " ('«', 0.08588345348834991),\n",
       " ('ещё', 0.07390445470809937)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vect.most_similar(positive=\"пёс\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('какой-то', 0.3257799446582794),\n",
       " ('генерал', 0.31632810831069946),\n",
       " ('который', 0.2939903438091278),\n",
       " ('сыр', 0.2812940776348114),\n",
       " ('дом', 0.2463790625333786),\n",
       " ('филипп', 0.23077917098999023),\n",
       " ('хвост', 0.21169646084308624),\n",
       " ('кроме', 0.1740206927061081),\n",
       " ('половина', 0.1687300056219101),\n",
       " ('год', 0.15672554075717926)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vect.most_similar(negative=[\"пёс\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the texts of works into vectors - take the sum of the vectors of all words that are included in the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8     [0.0011995971, 0.0026045498, -0.007123381, 0.0...\n",
       "0     [0.00060500286, 0.0009878661, -0.006436143, 0....\n",
       "6     [-0.0007017342, 0.0016293409, -0.0075600725, -...\n",
       "2     [0.0007468546, 0.005325895, 0.0029864938, -0.0...\n",
       "28    [-0.00034407602, 0.0011128776, -0.0044632014, ...\n",
       "9     [0.0016693913, 0.002875525, 0.0060309144, 0.00...\n",
       "10    [-0.0015563326, -0.0002351378, 0.0017460805, 0...\n",
       "3     [0.0014446821, 0.0006326371, 0.00046844853, -0...\n",
       "12    [0.001994996, -0.00026469494, 0.0009518385, -0...\n",
       "18    [0.003718499, 0.00039980255, 0.0016137686, -0....\n",
       "31    [0.0013373742, -0.0012804837, -0.0009447588, -...\n",
       "33    [0.0029800471, -0.0039259233, -0.0082993405, -...\n",
       "22    [-0.00031827067, 0.001542769, -0.004924734, -0...\n",
       "24    [0.0007858051, 0.0038820687, -0.0089516025, 0....\n",
       "27    [0.0051696994, 0.0043699583, 0.0005135621, -0....\n",
       "20    [-0.00013956544, -0.008477387, 0.0015005053, -...\n",
       "30    [0.0024541044, 0.002181918, -0.006962289, -0.0...\n",
       "16    [-0.0019121018, 0.0033137815, -0.002012539, -0...\n",
       "14    [-0.0007017342, 0.0016293409, -0.0075600725, -...\n",
       "23    [-5.6633555e-05, -0.00014515119, -0.0047778636...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text2vec(text):\n",
    "    # We average the word vectors\n",
    "    vecs = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            vecs.append(w2v_vect[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return np.sum(vecs, axis=0) / len(vecs)\n",
    "\n",
    "w2v_train = X_train_w2v.apply(text2vec)\n",
    "w2v_test = X_test_w2v.apply(text2vec)\n",
    "w2v_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.0500286e-04,  9.8786608e-04, -6.4361431e-03,  4.3950225e-03,\n",
       "       -2.1484522e-03,  4.3788948e-03, -3.2827668e-03, -1.5824639e-04,\n",
       "       -4.0768340e-04,  4.1240146e-03,  2.9832579e-03, -1.1184049e-03,\n",
       "        2.3771450e-03,  4.3791295e-03, -3.3780162e-03,  3.6893317e-03,\n",
       "       -3.0534176e-04, -3.6627722e-03,  4.2837071e-03,  1.1650639e-03,\n",
       "       -3.5849207e-03,  1.0118244e-03, -2.0437986e-03,  2.0544187e-03,\n",
       "        2.7699731e-03,  6.5018800e-03,  8.8855438e-04, -1.7634719e-03,\n",
       "       -2.3291865e-03,  7.5929239e-04, -3.1088262e-03, -6.5026688e-05,\n",
       "        1.0049879e-03,  2.7925286e-03,  2.9505072e-03,  5.3222585e-03,\n",
       "       -3.1152896e-03, -1.6914745e-03, -1.8096529e-04, -2.7003282e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train = np.dstack(w2v_train)[0]\n",
    "w2v_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_test = np.dstack(w2v_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_mean_w2v = np.sum(w2v_train[:, y_train == 0], axis=1)\n",
    "B_mean_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_mean_w2v = np.sum(w2v_train[:, y_train == 1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00278862,  0.0184991 , -0.01850843, -0.0024467 , -0.00360634,\n",
       "        0.02983524, -0.02856341, -0.00675855, -0.03277406,  0.00300739,\n",
       "        0.00173704, -0.01355877,  0.0197966 ,  0.02307998, -0.02244351,\n",
       "        0.04268904,  0.0029526 , -0.0270114 ,  0.02931669, -0.00776947,\n",
       "       -0.01001288, -0.02088375, -0.03144145,  0.03048296,  0.00445882,\n",
       "        0.02377772,  0.00154256,  0.00865296, -0.03854878,  0.00098113,\n",
       "       -0.01002669, -0.00201023,  0.00700065,  0.00874571,  0.00886993,\n",
       "        0.01820976,  0.00189508, -0.01905509,  0.00687913,  0.01687204],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_mean_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01558698, -0.00033955, -0.03569595, -0.0299675 ,  0.04458564,\n",
       "        0.01469893,  0.00961211,  0.00243056, -0.02241337, -0.01216594,\n",
       "       -0.0028644 ,  0.00267352, -0.01128724,  0.00255807, -0.00863056,\n",
       "        0.02452396, -0.00297498,  0.01021286,  0.02316547, -0.02574708,\n",
       "        0.0400386 , -0.00958712,  0.02340176,  0.02770709,  0.01332395,\n",
       "        0.04805974, -0.00208415,  0.02220017,  0.01985353, -0.01534151,\n",
       "       -0.00351909, -0.01365712, -0.01889437, -0.02396114,  0.0109638 ,\n",
       "        0.03646228, -0.0366723 , -0.00590722,  0.02159894,  0.01508343],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_mean_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bulgakov</th>\n",
       "      <th>Dostoevsky</th>\n",
       "      <th>predict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300927</td>\n",
       "      <td>0.533834</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.494668</td>\n",
       "      <td>0.544281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.603173</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.711181</td>\n",
       "      <td>0.820410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.525217</td>\n",
       "      <td>1.006180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.630667</td>\n",
       "      <td>0.233970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.930699</td>\n",
       "      <td>0.526922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.611738</td>\n",
       "      <td>0.506972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.317448</td>\n",
       "      <td>0.964613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.479375</td>\n",
       "      <td>0.457083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.699548</td>\n",
       "      <td>0.604553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.020287</td>\n",
       "      <td>0.592202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.325584</td>\n",
       "      <td>0.685958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.626422</td>\n",
       "      <td>0.420048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bulgakov  Dostoevsky  predict  class\n",
       "0   0.300927    0.533834      1.0    0.0\n",
       "1   0.494668    0.544281      1.0    0.0\n",
       "2   0.603173    0.223487      0.0    1.0\n",
       "3   0.711181    0.820410      1.0    0.0\n",
       "4   0.525217    1.006180      1.0    0.0\n",
       "5   0.630667    0.233970      0.0    1.0\n",
       "6   0.930699    0.526922      0.0    1.0\n",
       "7   0.611738    0.506972      0.0    1.0\n",
       "8   0.317448    0.964613      1.0    0.0\n",
       "9   0.479375    0.457083      0.0    1.0\n",
       "10  0.699548    0.604553      0.0    1.0\n",
       "11  1.020287    0.592202      0.0    1.0\n",
       "12  0.325584    0.685958      1.0    0.0\n",
       "13  0.626422    0.420048      0.0    0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "w2v_B = np.apply_along_axis(cosine, 0, w2v_test, v=B_mean_w2v)\n",
    "w2v_D = np.apply_along_axis(cosine, 0, w2v_test, v=D_mean_w2v)\n",
    "\n",
    "w2v_results = pd.DataFrame([\n",
<<<<<<< HEAD
    "    w2v_B,\n",
    "    w2v_D,\n",
    "    np.maximum(w2v_B, w2v_D) == w2v_D,\n",
    "    y_test], index=[\"Bulgakov\", \"Dostoevsky\", \"predict\", \"class\"]).T.astype(np.float)\n",
=======
    "    w2v_r,\n",
    "    w2v_l,\n",
    "    np.maximum(w2v_r, w2v_l) == w2v_l,\n",
    "    y_test], index=[\"Bulgakov\", \"Tolstoy\", \"predict\", \"class\"]).T.astype(np.float)\n",
>>>>>>> 02f68ff1eea8be139145b9dc5fd9e9fea4ffc987
    "w2v_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(w2v_results['predict'], w2v_results['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akimg/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier().fit(w2v_train.T, y_train.tolist()).score(w2v_test.T, y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
